{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7142f66-c8e8-4b10-9353-45941bbad34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "loaded_sentence_embeddings = torch.load(\"final_sentence_embeddings.pt\")\n",
    "loaded_sequence_embeddings = torch.load(\"final_sequence_embeddings.pt\")\n",
    "\n",
    "shot_count=torch.load('shot_count.pt')\n",
    "edit_trends=torch.load('edit_trends_labels.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7a3158-59b7-49e3-86b9-44b07b1ccae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shot_class=[]\n",
    "for i in range(len(shot_count)):\n",
    "    \n",
    "    if shot_count[i]<=20:\n",
    "        n_shot_class.append(0)\n",
    "    elif shot_count[i]>20 and shot_count[i]<=40:\n",
    "        n_shot_class.append(1)\n",
    "    elif shot_count[i]>40 and shot_count[i]<=60:\n",
    "        n_shot_class.append(2)\n",
    "    elif shot_count[i]>60:\n",
    "        n_shot_class.append(3)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5f1843-c269-4e72-b669-0c717f0aa356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shot_labs=torch.tensor(n_shot_class)\n",
    "n_shot_class_1hot=torch.zeros(shot_labs.size(0), 4)\n",
    "n_shot_class_1hot.scatter_(1, shot_labs.unsqueeze(1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50e16e9-48a7-4bc1-9893-15e94fb6c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_trends_lab=torch.tensor(edit_trends)\n",
    "edit_trends_1hot=torch.zeros(edit_trends_lab.size(0), 5)\n",
    "edit_trends_1hot.scatter_(1, edit_trends_lab.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5559ec-fa11-4870-b48b-01fd4b95b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567/510770044.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  len_lab=torch.tensor(n_shot_class_1hot, dtype=torch.float)\n",
      "/tmp/ipykernel_567/510770044.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trend_lab=torch.tensor(edit_trends_1hot, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#version with editing mix/trend and length label\n",
    "\n",
    "# Define the Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "# Define the Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Define the Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, label, emix):\n",
    "        # Concatenate label with src\n",
    "        src = torch.cat((src, label), dim=1)\n",
    "        src = torch.cat((src, emix), dim=1)\n",
    "        src = self.encoder(src)\n",
    "        output = self.decoder(src)\n",
    "        return output\n",
    "\n",
    "# Define the Cosine Similarity Loss\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        \n",
    "        output_normalized = F.normalize(output, p=2, dim=-1)\n",
    "        target_normalized = F.normalize(target, p=2, dim=-1)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = F.cosine_similarity(output_normalized, target_normalized, dim=-1)\n",
    "        \n",
    "        \n",
    "        loss = 1 - cosine_sim  \n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "dataset1 = loaded_sentence_embeddings  \n",
    "dataset2 = loaded_sequence_embeddings  \n",
    "\n",
    "len_lab=torch.tensor(n_shot_class_1hot, dtype=torch.float)\n",
    "trend_lab=torch.tensor(edit_trends_1hot, dtype=torch.float)\n",
    "dataset = TensorDataset(torch.FloatTensor(dataset1), torch.FloatTensor(dataset2), torch.FloatTensor(len_lab), torch.FloatTensor(trend_lab))\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "# Define the split ratio (e.g. 80% for training and 20% for testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split dataset into training and testing datasets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for both train and test datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "input_size = 768  \n",
    "hidden_size = 512  \n",
    "hidden_size_2 = 384  \n",
    "output_size = 256  \n",
    "\n",
    "#encoder = Encoder(input_size , hidden_size)\n",
    "encoder = Encoder(input_size + len(len_lab[0])+ len(trend_lab[0]), hidden_size)  # Adding label size to input_size\n",
    "decoder = Decoder(hidden_size, hidden_size_2, output_size)#working for 256 configuration\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# Loss and optimizer\n",
    "cosine_loss = CosineSimilarityLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 200\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    cosine_sim_accumulator = 0.0\n",
    "    num_samples = 0\n",
    "    for i, (input_data, target_data, label_data, trend_data) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(input_data, target_data, label_data, trend_data)\n",
    "        \n",
    "        # Compute the cosine similarity loss\n",
    "        loss = cosine_loss(output, target_data)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        output_normalized = F.normalize(output, p=2, dim=-1)\n",
    "        target_normalized = F.normalize(target_data, p=2, dim=-1)\n",
    "        cosine_sim = F.cosine_similarity(output_normalized, target_normalized, dim=-1)\n",
    "        cosine_sim_accumulator += cosine_sim.sum().item()\n",
    "        num_samples += output.size(0)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        avg_loss = running_loss / len(train_dataloader)\n",
    "        avg_cosine_sim = cosine_sim_accumulator / num_samples\n",
    "        print(f'Training - Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Avg Cosine Similarity: {avg_cosine_sim:.4f}')\n",
    "\n",
    "# Validation loop\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    val_running_loss = 0.0\n",
    "    val_cosine_sim_accumulator = 0.0\n",
    "    val_num_samples = 0\n",
    "    for input_data_val, target_data_val, label_data_val, trend_data_val in test_dataloader:\n",
    "        val_output = model(input_data_val, target_data_val, label_data_val, trend_data_val)\n",
    "        \n",
    "        # Compute the cosine similarity loss\n",
    "        val_loss = cosine_loss(val_output, target_data_val)\n",
    "        val_running_loss += val_loss.item()\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        val_output_normalized = F.normalize(val_output, p=2, dim=-1)\n",
    "        target_normalized_val = F.normalize(target_data_val, p=2, dim=-1)\n",
    "        val_cosine_sim = F.cosine_similarity(val_output_normalized, target_normalized_val, dim=-1)\n",
    "        val_cosine_sim_accumulator += val_cosine_sim.sum().item()\n",
    "        val_num_samples += val_output.size(0)\n",
    "    \n",
    "    avg_val_loss = val_running_loss / len(test_dataloader)\n",
    "    avg_val_cosine_sim = val_cosine_sim_accumulator / val_num_samples\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Avg Cosine Similarity: {avg_val_cosine_sim:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbc0065-ade8-40f1-b9c4-3730bb88e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_180/894204831.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(one_hot_labels, dtype=torch.float)\n",
      "/tmp/ipykernel_180/894204831.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  len_lab=torch.tensor(n_shot_class_1hot, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Training - Epoch [10/200], Loss: 0.0984, Avg Cosine Similarity: 0.9016\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Training - Epoch [20/200], Loss: 0.0930, Avg Cosine Similarity: 0.9070\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Training - Epoch [30/200], Loss: 0.0871, Avg Cosine Similarity: 0.9129\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Training - Epoch [40/200], Loss: 0.0822, Avg Cosine Similarity: 0.9178\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Training - Epoch [50/200], Loss: 0.0787, Avg Cosine Similarity: 0.9213\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "Training - Epoch [60/200], Loss: 0.0762, Avg Cosine Similarity: 0.9238\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "Training - Epoch [70/200], Loss: 0.0743, Avg Cosine Similarity: 0.9257\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "Training - Epoch [80/200], Loss: 0.0727, Avg Cosine Similarity: 0.9273\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "Training - Epoch [90/200], Loss: 0.0714, Avg Cosine Similarity: 0.9286\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Training - Epoch [100/200], Loss: 0.0703, Avg Cosine Similarity: 0.9297\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "Training - Epoch [110/200], Loss: 0.0694, Avg Cosine Similarity: 0.9306\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "Training - Epoch [120/200], Loss: 0.0686, Avg Cosine Similarity: 0.9314\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "Training - Epoch [130/200], Loss: 0.0679, Avg Cosine Similarity: 0.9322\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "Training - Epoch [140/200], Loss: 0.0672, Avg Cosine Similarity: 0.9328\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "Training - Epoch [150/200], Loss: 0.0666, Avg Cosine Similarity: 0.9334\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "Training - Epoch [160/200], Loss: 0.0661, Avg Cosine Similarity: 0.9339\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "Training - Epoch [170/200], Loss: 0.0657, Avg Cosine Similarity: 0.9343\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "Training - Epoch [180/200], Loss: 0.0652, Avg Cosine Similarity: 0.9348\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "Training - Epoch [190/200], Loss: 0.0647, Avg Cosine Similarity: 0.9353\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "Training - Epoch [200/200], Loss: 0.0644, Avg Cosine Similarity: 0.9356\n",
      "Validation Loss: 0.1297, Avg Cosine Similarity: 0.8701\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#version with only length label\n",
    "\n",
    "# Define the Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "# Define the Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Define the Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, label):\n",
    "        # Concatenate label with src\n",
    "        src = torch.cat((src, label), dim=1)\n",
    "        src = self.encoder(src)\n",
    "        output = self.decoder(src)\n",
    "        return output\n",
    "#\"\"\"\n",
    "# Define the Cosine Similarity Loss\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # Normalize the embeddings\n",
    "        output_normalized = F.normalize(output, p=2, dim=-1)\n",
    "        target_normalized = F.normalize(target, p=2, dim=-1)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = F.cosine_similarity(output_normalized, target_normalized, dim=-1)\n",
    "        \n",
    "        # Cosine similarity loss\n",
    "        loss = 1 - cosine_sim  # minimize the angle, maximize cosine similarity\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "    \n",
    "dataset1 = loaded_sentence_embeddings  \n",
    "dataset2 = loaded_sequence_embeddings  \n",
    "\n",
    "len_lab=torch.tensor(n_shot_class_1hot, dtype=torch.float)\n",
    "dataset = TensorDataset(torch.FloatTensor(dataset1), torch.FloatTensor(dataset2), torch.FloatTensor(len_lab))\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "# Define the split ratio (e.g. 80% for training and 20% for testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split dataset into training and testing datasets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for both train and test datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "input_size = 768  \n",
    "hidden_size = 512  \n",
    "hidden_size_2 = 384  \n",
    "output_size = 256  \n",
    "\n",
    "#encoder = Encoder(input_size , hidden_size)\n",
    "encoder = Encoder(input_size + len(len_lab[0]), hidden_size)  # Adding label size to input_size\n",
    "decoder = Decoder(hidden_size, hidden_size_2, output_size)#working for 256 configuration\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# Loss and optimizer\n",
    "cosine_loss = CosineSimilarityLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 200\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    cosine_sim_accumulator = 0.0\n",
    "    num_samples = 0\n",
    "    for i, (input_data, target_data, label_data) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(input_data, target_data, label_data)\n",
    "        \n",
    "        # Compute the cosine similarity loss\n",
    "        loss = cosine_loss(output, target_data)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        output_normalized = F.normalize(output, p=2, dim=-1)\n",
    "        target_normalized = F.normalize(target_data, p=2, dim=-1)\n",
    "        cosine_sim = F.cosine_similarity(output_normalized, target_normalized, dim=-1)\n",
    "        cosine_sim_accumulator += cosine_sim.sum().item()\n",
    "        num_samples += output.size(0)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        avg_loss = running_loss / len(train_dataloader)\n",
    "        avg_cosine_sim = cosine_sim_accumulator / num_samples\n",
    "        print(f'Training - Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Avg Cosine Similarity: {avg_cosine_sim:.4f}')\n",
    "\n",
    "# Validation loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    val_running_loss = 0.0\n",
    "    val_cosine_sim_accumulator = 0.0\n",
    "    val_num_samples = 0\n",
    "    for input_data_val, target_data_val, label_data_val in test_dataloader:\n",
    "        val_output = model(input_data_val, target_data_val, label_data_val)\n",
    "        \n",
    "        # Compute the cosine similarity loss\n",
    "        val_loss = cosine_loss(val_output, target_data_val)\n",
    "        val_running_loss += val_loss.item()\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        val_output_normalized = F.normalize(val_output, p=2, dim=-1)\n",
    "        target_normalized_val = F.normalize(target_data_val, p=2, dim=-1)\n",
    "        val_cosine_sim = F.cosine_similarity(val_output_normalized, target_normalized_val, dim=-1)\n",
    "        val_cosine_sim_accumulator += val_cosine_sim.sum().item()\n",
    "        val_num_samples += val_output.size(0)\n",
    "    \n",
    "    avg_val_loss = val_running_loss / len(test_dataloader)\n",
    "    avg_val_cosine_sim = val_cosine_sim_accumulator / val_num_samples\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Avg Cosine Similarity: {avg_val_cosine_sim:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
