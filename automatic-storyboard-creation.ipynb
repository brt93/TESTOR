{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub --quiet\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your Hugging Face API token here\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Log in to Hugging Face\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T23:40:24.604048Z",
     "iopub.status.busy": "2024-10-21T23:40:24.603223Z",
     "iopub.status.idle": "2024-10-21T23:40:52.597062Z",
     "shell.execute_reply": "2024-10-21T23:40:52.595841Z",
     "shell.execute_reply.started": "2024-10-21T23:40:24.604004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install diffusers[torch]\n",
    "!pip install peft\n",
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene prompts with characters' name (for Storyboard generation with characters Loras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scene_prompts = [\n",
    "    # List of prompts used to generated the storyboard, containing the characters' lora name.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene prompts without characters' names (for Storyboard generation with Base Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scene_prompts_no_characters = [\n",
    "    # List of prompts used to generated the storyboard, not containing the characters' lora name.\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Initial Storyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T14:03:03.947218Z",
     "iopub.status.busy": "2024-10-21T14:03:03.946867Z",
     "iopub.status.idle": "2024-10-21T14:44:10.167918Z",
     "shell.execute_reply": "2024-10-21T14:44:10.165039Z",
     "shell.execute_reply.started": "2024-10-21T14:03:03.947189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# CREATE INFERENCE PIPELINE\n",
    "model = \"SG161222/Realistic_Vision_V5.1_noVAE\"\n",
    "# Set up the pipeline\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    model, torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "# LOAD LORA WEIGHTS FOR SHOT TYPES AND CHARACTERS\n",
    "pipeline.unload_lora_weights()\n",
    "\n",
    "# Load shot type Loras if enabled\n",
    "def load_shot_type_loras():\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"closeup\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"mediumshot\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"fullshot\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"longshot\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"americanshot\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"extremelongshot\")\n",
    "    pipeline.load_lora_weights(\"/path/to/shottype/lora/weights\", adapter_name=\"extremecloseup\")\n",
    "\n",
    "# Load character Loras if enabled\n",
    "def load_character_loras():\n",
    "    pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"kaitoyosuke\")\n",
    "    pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"margojobeth\")\n",
    "    pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"cathrinannett\")\n",
    "    pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"caseykensley\")\n",
    "    \n",
    "\n",
    "# SET INFERENCE PARAMETERS\n",
    "width = 512\n",
    "height = 512\n",
    "neg = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, worst quality, low quality, blended faces, duplicate, mixed faces, ugly, morbid, bad anatomy\"\n",
    "num_inference_steps = 50\n",
    "guidance_scale = 7.5\n",
    "\n",
    "\n",
    "# SEARCH AND ACTIVATE RELEVANT ADAPTERS FOR THE SPECIFIC PROMPT\n",
    "def set_lora_adapters_from_prompt(pipeline, prompt, use_shot_types=True, use_characters=True):\n",
    "    # Define the shot type adapter names\n",
    "    shot_types = {\n",
    "        \"extreme close up\": \"extremecloseup\",\n",
    "        \"close up\": \"closeup\",\n",
    "        \"medium shot\": \"mediumshot\",\n",
    "        \"medium close up shot\": \"mediumshot\", \n",
    "        \"american shot\": \"americanshot\",\n",
    "        \"full body\": \"fullshot\",\n",
    "        \"long shot\": \"longshot\",\n",
    "        \"extreme long shot\": \"extremelongshot\"\n",
    "    }\n",
    "\n",
    "    # Define the character adapter names\n",
    "    character_adapters = [\"cathrinannett\", \"margojobeth\", \"kaitoyosuke\", \"caseykensley\"]  \n",
    "\n",
    "    # Default adapter lists\n",
    "    active_adapters = []\n",
    "    adapter_weights = []\n",
    "\n",
    "    # Add shot type adapters if enabled\n",
    "    if use_shot_types:\n",
    "        for shot, adapter in shot_types.items():\n",
    "            if shot in prompt.lower():\n",
    "                active_adapters.append(adapter)\n",
    "                adapter_weights.append(1.0)\n",
    "\n",
    "    # Add character adapters if enabled\n",
    "    if use_characters:\n",
    "        for character in character_adapters:\n",
    "            if character in prompt.lower():\n",
    "                active_adapters.append(character)\n",
    "                if \"extreme close up\" in prompt.lower() or \"close up\" in prompt.lower() or \"medium shot\" in prompt.lower() or \"medium close up shot\" in prompt.lower():\n",
    "                    adapter_weights.append(0.9)\n",
    "                else:\n",
    "                    adapter_weights.append(0.8)\n",
    "            \n",
    "\n",
    "    # Activate the adapters\n",
    "    if active_adapters:\n",
    "        pipeline.set_adapters(active_adapters, adapter_weights=adapter_weights)\n",
    "        print(f\"Active adapters: {active_adapters} with weights {adapter_weights}\")\n",
    "    else:\n",
    "        print(\"No adapters activated.\")\n",
    "\n",
    "\n",
    "# GENERATE 4 IMAGES FOR THE SPECIFIC PROMPT\n",
    "def generate_images_for_prompt(prompt, num_images=4, use_shot_types=True, use_characters=True):\n",
    "    set_lora_adapters_from_prompt(pipeline, prompt, use_shot_types=use_shot_types, use_characters=use_characters)\n",
    "    images = []\n",
    "    for i in range(num_images):\n",
    "        image = pipeline(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, negative_prompt=neg, width=width, height=height).images[0]\n",
    "        print(f\"Generated image {i + 1}\")\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "# GENERATE, DISPLAY AND SELECTION OF IMAGES FOR THE SPECIFIC PROMPT\n",
    "def generate_display_and_select_image(prompt, use_shot_types=True, use_characters=True):\n",
    "    selected_image = None\n",
    "    current_prompt = prompt\n",
    "\n",
    "    while selected_image is None:\n",
    "        # Generate images based on the current prompt\n",
    "        images = generate_images_for_prompt(current_prompt, use_shot_types=use_shot_types, use_characters=use_characters)\n",
    "\n",
    "        # Display images horizontally\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "        for i, img in enumerate(images):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Image {i+1}\")\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Ask the user to select an image or regenerate\n",
    "        user_input = input(f\"Select the image (1-{len(images)}) or type 'r' to regenerate images: \").strip().lower()\n",
    "\n",
    "        if user_input == 'r':\n",
    "            modify_prompt = input(\"Would you like to modify the prompt? (y/n): \").strip().lower()\n",
    "            if modify_prompt == 'y':\n",
    "                current_prompt = input(f\"Enter a new prompt (original: '{prompt}'): \").strip()\n",
    "        else:\n",
    "            try:\n",
    "                selection = int(user_input)\n",
    "                if 1 <= selection <= len(images):\n",
    "                    selected_image = images[selection - 1]\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Please select a number between 1 and {len(images)}.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a valid image number or 'r' to regenerate.\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return selected_image\n",
    "\n",
    "\n",
    "# DISPLAY THE FINAL STORYBOARD\n",
    "def display_storyboard(selected_images):\n",
    "    print(\"Displaying the final storyboard with selected images:\")\n",
    "    num_images = len(selected_images)\n",
    "    cols = 2\n",
    "    rows = math.ceil(num_images / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img in enumerate(selected_images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Prompt {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_storyboard(prompts, save_dir, use_shot_types=True, use_characters=True):\n",
    "\n",
    "    # Conditionally load shot type and character LoRA weights based on user selection\n",
    "    pipeline.unload_lora_weights()  # Ensure a clean start with no loaded weights\n",
    "    \n",
    "    if use_shot_types:\n",
    "        load_shot_type_loras()\n",
    "    \n",
    "    if use_characters:\n",
    "        load_character_loras()\n",
    "\n",
    "    selected_images = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        selected_image = generate_display_and_select_image(prompt, use_shot_types=use_shot_types, use_characters=use_characters)\n",
    "        img_index = len(os.listdir(save_dir))\n",
    "        img_filename = f\"shot_{img_index}.png\"\n",
    "        img_path = os.path.join(save_dir, img_filename)\n",
    "        selected_image.save(img_path)\n",
    "        selected_images.append(selected_image)\n",
    "        print(f\"Selected image saved to: {img_path}\")\n",
    "\n",
    "    display_storyboard(selected_images)\n",
    "\n",
    "\n",
    "# SCENE PROMPTS\n",
    "scene_prompts = []\n",
    "\n",
    "# SCENE STORYBOARD DIRECTORY\n",
    "output_dir = ''\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Specify whether to use shot types and character LoRAs\n",
    "# Setting both to none will use the base realistic vision model\n",
    "use_shot_types = True\n",
    "use_characters = True\n",
    "\n",
    "generate_storyboard(scene_prompts, output_dir, use_shot_types=use_shot_types, use_characters=use_characters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Storyboard (No inpainting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Function to load and sort images based on their shot number in the filename\n",
    "def load_images_from_directory(directory):\n",
    "    # Use regex to extract the numerical part from filenames (like 'shot_1', 'shot_2', etc.)\n",
    "    def extract_shot_number(filename):\n",
    "        match = re.search(r'shot_(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))  # Extract the number after 'shot_'\n",
    "        return float('inf')  # If no number is found, send it to the end of the list\n",
    "\n",
    "    # Get all PNG images and sort by shot number\n",
    "    image_paths = sorted([os.path.join(directory, img) for img in os.listdir(directory) if img.endswith('.png')],\n",
    "                         key=lambda x: extract_shot_number(os.path.basename(x)))\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# Display storyboard function\n",
    "def display_storyboard(image_paths):\n",
    "    print(\"Displaying the final storyboard with images from the directory:\")\n",
    "    \n",
    "    num_images = len(image_paths)\n",
    "    cols = 2  # Set the number of columns for the storyboard grid\n",
    "    rows = math.ceil(num_images / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Shot {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Directory where the storyboard images are saved\n",
    "storyboard_dir = ''\n",
    "\n",
    "# Load images from the storyboard4 directory\n",
    "image_paths = load_images_from_directory(storyboard_dir)\n",
    "\n",
    "# Display the storyboard images\n",
    "display_storyboard(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting Characters Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T15:21:44.493712Z",
     "iopub.status.busy": "2024-10-21T15:21:44.493255Z",
     "iopub.status.idle": "2024-10-21T15:26:07.380174Z",
     "shell.execute_reply": "2024-10-21T15:26:07.379124Z",
     "shell.execute_reply.started": "2024-10-21T15:21:44.493677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Set the output directory\n",
    "output_dir = ''\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set up the Stable Diffusion inpainting pipeline\n",
    "pipeline = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"krnl/stable-diffusion-v15-inpainting\", torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "# Load character loras:\n",
    "pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"kaitoyosuke\")\n",
    "pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"margojobeth\")\n",
    "pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"cathrinannett\")\n",
    "pipeline.load_lora_weights(\"/path/to/character/lora/weights\", adapter_name=\"caseykensley\")\n",
    "\n",
    "\n",
    "# Detect people in the image selected for inpainting\n",
    "def create_mask(image_path):\n",
    "    \n",
    "    max_people=4 #Max number people to detect\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detectron2 setup for object detection\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    outputs = predictor(image_rgb)\n",
    "\n",
    "    # Get masks and bounding boxes for detected persons\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    masks = instances.pred_masks.numpy()\n",
    "    classes = instances.pred_classes.numpy()\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "\n",
    "    person_class_id = 0\n",
    "    person_indices = [i for i in range(len(classes)) if classes[i] == person_class_id]\n",
    "\n",
    "    # Limit the number of detected people to `max_people`\n",
    "    person_indices = person_indices[:max_people]\n",
    "\n",
    "    if len(person_indices) == 0:\n",
    "        print(\"No persons detected.\")\n",
    "        return None, None\n",
    "\n",
    "    image_copy = image_rgb.copy()\n",
    "    for i in person_indices:\n",
    "        box = boxes[i]\n",
    "        cv2.rectangle(image_copy, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), 2)\n",
    "        cv2.putText(image_copy, f\"Person {i+1}\", (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(image_copy)\n",
    "    plt.title(\"Select Person\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    selected_index = int(input(f\"Select a person (1-{len(person_indices)}): \")) - 1\n",
    "    selected_mask = masks[person_indices[selected_index]]\n",
    "\n",
    "    selected_mask_uint8 = (selected_mask * 255).astype(np.uint8)\n",
    "    selected_mask_image = Image.fromarray(selected_mask_uint8)\n",
    "    selected_mask_image_path = os.path.join(output_dir, \"mask.png\")\n",
    "    selected_mask_image.save(selected_mask_image_path)\n",
    "\n",
    "    return image_rgb, selected_mask_image_path\n",
    "\n",
    "\n",
    "# Activate relevant Loras for the specific prompt\n",
    "def set_character_lora_adapters_from_prompt(pipeline, prompt):\n",
    "    # Define the character adapter names\n",
    "    character_adapters = [\"cathrinannett\", \"caseykensley\", \"margojobeth\", \"kaitoyosuke\"]  # Add other characters here if needed\n",
    "\n",
    "    # Default adapter lists\n",
    "    active_adapters = []\n",
    "    adapter_weights = []\n",
    "\n",
    "    # Search for character adapters in the prompt and set weight to one\n",
    "    for character in character_adapters:\n",
    "        if character in prompt.lower():\n",
    "            active_adapters.append(character)\n",
    "            adapter_weights.append(1) \n",
    "\n",
    "    # Set the adapters in the pipeline if any characters are detected\n",
    "    if active_adapters:\n",
    "        pipeline.set_adapters(active_adapters, adapter_weights=adapter_weights)\n",
    "        print(f\"Activated adapters: {active_adapters} with weights {adapter_weights}\")\n",
    "    else:\n",
    "        print(\"No character adapters activated.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inpaint_image(image_path):\n",
    "\n",
    "    # Create the mask\n",
    "    init_image, mask_image_path = create_mask(image_path)\n",
    "    if init_image is None:\n",
    "        print(\"Skipping inpainting as no persons were detected.\")\n",
    "        return None\n",
    "\n",
    "    # Show the selected image for inpainting\n",
    "    init_image_pil = Image.fromarray(init_image)\n",
    "    plt.imshow(init_image_pil)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Selected Image for Inpainting\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Prompt for inpainting\n",
    "    prompt = input(\"Enter the prompt for inpainting: \")\n",
    "    negative_prompt = \"bad anatomy, deformed, ugly, disfigured\"\n",
    "    \n",
    "    set_character_lora_adapters_from_prompt(pipeline, prompt)\n",
    "\n",
    "    # Load images\n",
    "    init_image = load_image(image_path)\n",
    "    mask_image = load_image(mask_image_path)\n",
    "\n",
    "    # Perform inpainting, generating 4 different results\n",
    "    inpainted_images = []\n",
    "    for i in range(4):\n",
    "        inpainted_image = pipeline(\n",
    "            prompt=prompt, \n",
    "            negative_prompt=negative_prompt, \n",
    "            image=init_image, \n",
    "            mask_image=mask_image\n",
    "        ).images[0]\n",
    "        inpainted_images.append(inpainted_image)\n",
    "\n",
    "    \n",
    "    # Display the inpainted images horizontally\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 1 row, 4 columns\n",
    "    for i, img in enumerate(inpainted_images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Inpainted Image {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Ask the user if they want to discard or select an image to save\n",
    "    while True:\n",
    "        user_input = input(\"Enter the number of the image to save (1-4), or 'd' to discard all: \").strip().lower()\n",
    "        if user_input == 'd':\n",
    "            print(\"All inpainted images discarded.\")\n",
    "            return None\n",
    "        try:\n",
    "            selected_index = int(user_input) - 1\n",
    "            if 0 <= selected_index < 4:\n",
    "                selected_image = inpainted_images[selected_index]\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Please enter a valid number between 1 and 4.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number or 'd' to discard.\")\n",
    "    \n",
    "    # Save the selected image\n",
    "    inpainted_image_path = os.path.join(output_dir, os.path.basename(image_path))  # Save with the same filename\n",
    "    selected_image.save(inpainted_image_path)\n",
    "    print(f\"Selected inpainted image saved to: {inpainted_image_path}\")\n",
    "    return inpainted_image_path  \n",
    "\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    # Define a function to extract the shot number from the filename\n",
    "    def extract_shot_number(filename):\n",
    "        match = re.search(r'shot_(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))  # Convert the number to an integer\n",
    "        return float('inf')  # If no match, send it to the end of the list\n",
    "\n",
    "    # Load all images from the given directory\n",
    "    image_paths = [os.path.join(directory, img) for img in os.listdir(directory) if img.endswith('.png')]\n",
    "\n",
    "    # Sort the images by the shot number extracted from the filename\n",
    "    image_paths = sorted(image_paths, key=lambda x: extract_shot_number(os.path.basename(x)))\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def display_storyboard(image_paths):\n",
    "    images = [Image.open(img_path) for img_path in image_paths]\n",
    "    \n",
    "    num_images = len(images)\n",
    "    cols = 2\n",
    "    rows = math.ceil(num_images / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Image {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def interactive_inpainting(storyboard_dir):\n",
    "\n",
    "    image_paths = load_images_from_directory(storyboard_dir)\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in the directory: {storyboard_dir}\")\n",
    "        return\n",
    "    while True:\n",
    "        response = input(f\"Would you like to inpaint any images? (Enter image index 1-{len(image_paths)} or 'no'): \").strip().lower()\n",
    "        if response == 'no':\n",
    "            break\n",
    "        try:\n",
    "            index = int(response) - 1\n",
    "            if 0 <= index < len(image_paths):\n",
    "                new_image_path = inpaint_image(image_paths[index])\n",
    "                if new_image_path:\n",
    "                    image_paths[index] = new_image_path  # Replace original with inpainted image\n",
    "            else:\n",
    "                print(f\"Please enter a valid index between 1 and {len(image_paths)}.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number or 'no'.\")\n",
    "\n",
    "    # Once inpainting is done, display the final storyboard\n",
    "    display_storyboard(image_paths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Directory where the new inpainted storyboard images are saved\n",
    "storyboard_dir =''\n",
    "\n",
    "\n",
    "# Start the inpainting interaction\n",
    "interactive_inpainting(storyboard_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Final Storyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Function to load and sort images based on their shot number in the filename\n",
    "def load_images_from_directory(directory):\n",
    "    # Use regex to extract the numerical part from filenames (like 'shot_1', 'shot_2', etc.)\n",
    "    def extract_shot_number(filename):\n",
    "        match = re.search(r'shot_(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))  # Extract the number after 'shot_'\n",
    "        return float('inf')  # If no number is found, send it to the end of the list\n",
    "\n",
    "    # Get all PNG images and sort by shot number\n",
    "    image_paths = sorted([os.path.join(directory, img) for img in os.listdir(directory) if img.endswith('.png')],\n",
    "                         key=lambda x: extract_shot_number(os.path.basename(x)))\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# Display storyboard function\n",
    "def display_storyboard(directory):\n",
    "    \n",
    "    print(\"Displaying the final storyboard with images from the directory:\")\n",
    "    image_paths = load_images_from_directory(directory)\n",
    "    \n",
    "    num_images = len(image_paths)\n",
    "    cols = 2  \n",
    "    rows = math.ceil(num_images / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Shot {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def create_final_storyboard(storyboard_dir, inpainting_dir, final_storyboard_dir):\n",
    "    # Create the final storyboard directory if it doesn't exist\n",
    "    os.makedirs(final_storyboard_dir, exist_ok=True)\n",
    "    \n",
    "    # Load all the original images from the storyboard directory\n",
    "    original_images = load_images_from_directory(storyboard_dir)\n",
    "    \n",
    "    # Load all inpainted images from the inpainting directory\n",
    "    inpainted_images = load_images_from_directory(inpainting_dir)\n",
    "    \n",
    "    # Create a dictionary for the inpainted images by filename\n",
    "    inpainted_dict = {os.path.basename(img): img for img in inpainted_images}\n",
    "    \n",
    "    # Iterate over the original images and either copy the inpainted or the original image to the final folder\n",
    "    for original_image in original_images:\n",
    "        original_filename = os.path.basename(original_image)\n",
    "        \n",
    "        # Check if the inpainted version exists, if so, copy the inpainted version\n",
    "        if original_filename in inpainted_dict:\n",
    "            final_image_path = os.path.join(final_storyboard_dir, original_filename)\n",
    "            shutil.copy(inpainted_dict[original_filename], final_image_path)\n",
    "            print(f\"Inpainted image '{original_filename}' copied to final storyboard.\")\n",
    "        else:\n",
    "            # Copy the original image if no inpainted version exists\n",
    "            final_image_path = os.path.join(final_storyboard_dir, original_filename)\n",
    "            shutil.copy(original_image, final_image_path)\n",
    "            print(f\"Original image '{original_filename}' copied to final storyboard.\")\n",
    "\n",
    "    print(f\"Final storyboard created at: {final_storyboard_dir}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# Directory where the original storyboard images are saved \n",
    "storyboard_dir = ''\n",
    "\n",
    "# Directory where the inpainted storyboard images are saved \n",
    "inpainting_dir =''\n",
    "\n",
    "# Directory where to save the final storyboard\n",
    "final_storyboard_dir = ''\n",
    "os.makedirs(final_storyboard_dir, exist_ok=True)\n",
    "\n",
    "create_final_storyboard(storyboard_dir, inpainting_dir, final_storyboard_dir)\n",
    "\n",
    "display_storyboard(final_storyboard_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Final Storyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r final_storyboard3.zip '/kaggle/working/scene-3/v2/storyboard'\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'final_storyboard3.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5667426,
     "sourceId": 9665930,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5619105,
     "sourceId": 9674823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
