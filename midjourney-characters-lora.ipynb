{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login to HuggingFace + install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub --quiet\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your Hugging Face API token here\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Log in to Hugging Face\n",
    "login(hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install peft\n",
    "\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "!pip install -e diffusers\n",
    "\n",
    "%cd diffusers/examples/dreambooth\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cathrin Annett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\  \n",
    "  --pretrained_model_name_or_path=\"benjamin-paine/stable-diffusion-v1-5\" \\\n",
    "  --instance_data_dir=\"/path/to/character/input/dataset\" \\\n",
    "  --class_data_dir=\"/path/to/woman/regularization/dataset\" \\\n",
    "  --output_dir=\"/path/to/character/output/directory\" \\\n",
    "  --instance_prompt=\"picture of cathrinannett woman\" \\\n",
    "  --class_prompt=\"picture of a woman\" \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --use_8bit_adam \\\n",
    "  --train_text_encoder \\\n",
    "  --resolution=512 \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_train_epochs=4 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaito Yosuke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"benjamin-paine/stable-diffusion-v1-5\" \\\n",
    "  --instance_data_dir=\"/path/to/character/input/dataset\" \\\n",
    "  --class_data_dir=\"/path/to/man/regularization/dataset\" \\\n",
    "  --output_dir=\"/path/to/character/output/directory\" \\\n",
    "  --instance_prompt=\"picture of kaitoyosuke man\" \\\n",
    "  --class_prompt=\"picture of a man\" \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --use_8bit_adam \\\n",
    "  --train_text_encoder \\\n",
    "  --resolution=512 \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_train_epochs=4 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margo Jobeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"benjamin-paine/stable-diffusion-v1-5\" \\\n",
    "  --instance_data_dir=\"/path/to/character/input/dataset\" \\\n",
    "  --class_data_dir=\"/path/to/woman/regularization/dataset\" \\\n",
    "  --output_dir=\"/path/to/character/output/directory\" \\\n",
    "  --instance_prompt=\"picture of margojobeth woman\" \\\n",
    "  --class_prompt=\"picture of a woman\" \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --use_8bit_adam \\\n",
    "  --train_text_encoder \\\n",
    "  --resolution=512 \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_train_epochs=4 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Casey Kensley</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"benjamin-paine/stable-diffusion-v1-5\" \\\n",
    "  --instance_data_dir=\"/path/to/character/input/dataset\" \\\n",
    "  --output_dir=\"/path/to/character/output/directory\" \\\n",
    "  --instance_prompt=\"picture of caseykensley boy\" \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --use_8bit_adam \\\n",
    "  --train_text_encoder \\\n",
    "  --resolution=512 \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_train_epochs=4 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --mixed_precision=\"fp16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y diffusers\n",
    "!pip install diffusers[torch]\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T18:19:56.995434Z",
     "iopub.status.busy": "2024-11-05T18:19:56.994846Z",
     "iopub.status.idle": "2024-11-05T18:20:07.075228Z",
     "shell.execute_reply": "2024-11-05T18:20:07.074412Z",
     "shell.execute_reply.started": "2024-11-05T18:19:56.995400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Crea la pipeline con i componenti caricati\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/Realistic_Vision_V5.1_noVAE\",torch_dtype=torch.float16  \n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and activate character Lora +  set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T18:22:54.365977Z",
     "iopub.status.busy": "2024-11-05T18:22:54.365571Z",
     "iopub.status.idle": "2024-11-05T18:22:54.840173Z",
     "shell.execute_reply": "2024-11-05T18:22:54.839359Z",
     "shell.execute_reply.started": "2024-11-05T18:22:54.365945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pipeline.unload_lora_weights()\n",
    "pipeline.load_lora_weights(\"/path/to/character/output/weights\", adapter_name=\"cathrinannett\") \n",
    "pipeline.set_adapters([\"cathrinannett\"])\n",
    "save_dir = \"/path/to/output/character/generated/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pipeline.unload_lora_weights()\n",
    "pipeline.load_lora_weights(\"/path/to/character/output/weights\", adapter_name=\"kaitoyosuke\")\n",
    "pipeline.set_adapters([\"kaitoyosuke\"])\n",
    "save_dir = \"/path/to/output/character/generated/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pipeline.unload_lora_weights()\n",
    "pipeline.load_lora_weights(\"/path/to/character/output/weights\", adapter_name=\"margojobeth\")\n",
    "pipeline.set_adapters([\"margojobeth\"])\n",
    "save_dir = \"/path/to/output/character/generated/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.unload_lora_weights()\n",
    "pipeline.load_lora_weights(\"/path/to/character/output/weights\", adapter_name=\"caseykensley\")\n",
    "pipeline.set_adapters([\"caseykensley\"])\n",
    "save_dir = \"/path/to/output/character/generated/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T18:22:58.794789Z",
     "iopub.status.busy": "2024-11-05T18:22:58.794405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "prompts = [\n",
    "     # List of prompts used to perform inference with the character's lora.\n",
    "]\n",
    "\n",
    "\n",
    "neg = \"deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, bad anatomy, low quality, ugly, bad limbs, bad face, deformed, blurry eyes, multiple fingers, missing digits, missing legs, extra digits, bad hands, lowres, blended faces, duplicate, mixed faces, jpeg artifacts, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, blurry, dehydrated, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    num_images = 2 # Generate 2 images per prompt\n",
    "    images = []\n",
    "    for i in range(num_images):\n",
    "        image = pipeline(prompt, num_inference_steps=50, guidance_scale=7.5, negative_prompt=neg).images[0]\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        #image_path = os.path.join(save_dir, f\"{prompt}_{i}.png\")\n",
    "        #image.save(image_path) # Optionally save each image\n",
    "        images.append(image)\n",
    "\n",
    "    # Create a grid of the 2 images\n",
    "    grid_cols = 2\n",
    "    grid_rows = 1\n",
    "    fig, axs = plt.subplots(grid_rows, grid_cols, figsize=(6, 4))\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Save the grid image\n",
    "    grid_image_path = os.path.join(save_dir, f\"{prompt.replace(' ', '_')}_grid.png\")\n",
    "    plt.savefig(grid_image_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r file.zip /path/to/folder    # Specify the folder to download\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'file.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5396268,
     "sourceId": 9053445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5498274,
     "sourceId": 9109873,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5875975,
     "sourceId": 9626151,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5787722,
     "sourceId": 9650747,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5788701,
     "sourceId": 9782800,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5788313,
     "sourceId": 9789872,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5783374,
     "sourceId": 9802633,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6008099,
     "sourceId": 9802668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
